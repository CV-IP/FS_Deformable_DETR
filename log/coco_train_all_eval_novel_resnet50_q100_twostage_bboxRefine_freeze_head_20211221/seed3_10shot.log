| distributed init (rank 7): env://
| distributed init (rank 6): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 5): env://
| distributed init (rank 3): env://
| distributed init (rank 4): env://
| distributed init (rank 0): env://
n130-019-195:1129985:1129985 [0] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129985:1129985 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129985:1129985 [0] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
NCCL version 2.4.8+cuda10.2
n130-019-195:1129995:1129995 [5] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129998:1129998 [7] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129987:1129987 [1] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129991:1129991 [3] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129993:1129993 [4] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129997:1129997 [6] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129995:1129995 [5] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129987:1129987 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129991:1129991 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129998:1129998 [7] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129993:1129993 [4] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129997:1129997 [6] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129989:1129989 [2] NCCL INFO Bootstrap : Using [0]eth0:10.130.19.195<0> [1]eth2:10.130.19.131<0>
n130-019-195:1129989:1129989 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
n130-019-195:1129987:1129987 [1] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129995:1129995 [5] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129991:1129991 [3] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129998:1129998 [7] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129993:1129993 [4] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129997:1129997 [6] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129989:1129989 [2] NCCL INFO NET/IB : Using [0]mlx5_2:1/RoCE [1]mlx5_0:1/RoCE ; OOB eth0:10.130.19.195<0>
n130-019-195:1129985:1130549 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff
n130-019-195:1129995:1130562 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000
n130-019-195:1129987:1130561 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff
n130-019-195:1129998:1130564 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000
n130-019-195:1129991:1130563 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff
n130-019-195:1129989:1130570 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff
n130-019-195:1129997:1130568 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000
n130-019-195:1129993:1130567 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 00 :    0   1   2   3   4   5   6   7
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 01 :    0   2   3   1   6   4   5   7
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 02 :    0   2   5   7   4   6   1   3
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 03 :    0   3   1   6   4   7   5   2
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 04 :    0   7   5   4   6   1   3   2
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 05 :    0   7   6   5   4   3   2   1
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 06 :    0   1   2   3   4   5   6   7
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 07 :    0   2   3   1   6   4   5   7
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 08 :    0   2   5   7   4   6   1   3
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 09 :    0   3   1   6   4   7   5   2
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 10 :    0   7   5   4   6   1   3   2
n130-019-195:1129985:1130549 [0] NCCL INFO Channel 11 :    0   7   6   5   4   3   2   1
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 00 : 5[5] -> 6[6] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 00 : 7[7] -> 0[0] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 00 : 6[6] -> 7[7] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 00 : 3[3] -> 4[4] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 00 : 4[4] -> 5[5] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 01 : 2[2] -> 3[3] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 01 : 1[1] -> 6[6] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 01 : 5[5] -> 7[7] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 01 : 7[7] -> 0[0] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 01 : 6[6] -> 4[4] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 01 : 3[3] -> 1[1] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 01 : 4[4] -> 5[5] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 01 : 0[0] -> 2[2] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 02 : 5[5] -> 7[7] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 02 : 3[3] -> 0[0] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 02 : 0[0] -> 2[2] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 02 : 2[2] -> 5[5] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 02 : 7[7] -> 4[4] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 02 : 1[1] -> 3[3] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 02 : 4[4] -> 6[6] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 02 : 6[6] -> 1[1] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 03 : 2[2] -> 0[0] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 03 : 5[5] -> 2[2] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 03 : 3[3] -> 1[1] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 03 : 7[7] -> 5[5] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 03 : 0[0] -> 3[3] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 03 : 1[1] -> 6[6] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 03 : 6[6] -> 4[4] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 03 : 4[4] -> 7[7] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 04 : 2[2] -> 0[0] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 04 : 1[1] -> 3[3] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 04 : 5[5] -> 4[4] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 04 : 3[3] -> 2[2] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 04 : 7[7] -> 5[5] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 04 : 6[6] -> 1[1] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 04 : 0[0] -> 7[7] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 04 : 4[4] -> 6[6] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 05 : 1[1] -> 0[0] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 05 : 5[5] -> 4[4] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 05 : 3[3] -> 2[2] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 05 : 6[6] -> 5[5] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 05 : 0[0] -> 7[7] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 05 : 2[2] -> 1[1] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 05 : 7[7] -> 6[6] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 05 : 4[4] -> 3[3] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 06 : 1[1] -> 2[2] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 06 : 2[2] -> 3[3] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 06 : 5[5] -> 6[6] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 06 : 3[3] -> 4[4] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 06 : 6[6] -> 7[7] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 06 : 7[7] -> 0[0] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 06 : 0[0] -> 1[1] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 06 : 4[4] -> 5[5] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 07 : 1[1] -> 6[6] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 07 : 2[2] -> 3[3] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 07 : 5[5] -> 7[7] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 07 : 3[3] -> 1[1] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 07 : 6[6] -> 4[4] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 07 : 7[7] -> 0[0] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 07 : 0[0] -> 2[2] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 07 : 4[4] -> 5[5] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 08 : 1[1] -> 3[3] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 08 : 2[2] -> 5[5] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 08 : 5[5] -> 7[7] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 08 : 3[3] -> 0[0] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 08 : 6[6] -> 1[1] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 08 : 7[7] -> 4[4] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 08 : 0[0] -> 2[2] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 08 : 4[4] -> 6[6] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 09 : 1[1] -> 6[6] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 09 : 2[2] -> 0[0] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 09 : 5[5] -> 2[2] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 09 : 3[3] -> 1[1] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 09 : 6[6] -> 4[4] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 09 : 7[7] -> 5[5] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 09 : 0[0] -> 3[3] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 09 : 4[4] -> 7[7] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 10 : 1[1] -> 3[3] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 10 : 2[2] -> 0[0] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 10 : 5[5] -> 4[4] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 10 : 3[3] -> 2[2] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 10 : 6[6] -> 1[1] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 10 : 7[7] -> 5[5] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 10 : 0[0] -> 7[7] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 10 : 4[4] -> 6[6] via P2P/IPC
n130-019-195:1129987:1130561 [1] NCCL INFO Ring 11 : 1[1] -> 0[0] via P2P/IPC
n130-019-195:1129989:1130570 [2] NCCL INFO Ring 11 : 2[2] -> 1[1] via P2P/IPC
n130-019-195:1129991:1130563 [3] NCCL INFO Ring 11 : 3[3] -> 2[2] via P2P/IPC
n130-019-195:1129995:1130562 [5] NCCL INFO Ring 11 : 5[5] -> 4[4] via P2P/IPC
n130-019-195:1129997:1130568 [6] NCCL INFO Ring 11 : 6[6] -> 5[5] via P2P/IPC
n130-019-195:1129998:1130564 [7] NCCL INFO Ring 11 : 7[7] -> 6[6] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Ring 11 : 0[0] -> 7[7] via P2P/IPC
n130-019-195:1129993:1130567 [4] NCCL INFO Ring 11 : 4[4] -> 3[3] via P2P/IPC
n130-019-195:1129985:1130549 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled
n130-019-195:1129989:1130570 [2] NCCL INFO comm 0x7fed340028b0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 - Init COMPLETE
n130-019-195:1129987:1130561 [1] NCCL INFO comm 0x7fcc040028b0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 - Init COMPLETE
n130-019-195:1129991:1130563 [3] NCCL INFO comm 0x7f53300028b0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 - Init COMPLETE
n130-019-195:1129995:1130562 [5] NCCL INFO comm 0x7f0ac40028b0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 - Init COMPLETE
n130-019-195:1129997:1130568 [6] NCCL INFO comm 0x7fb9c80028b0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 - Init COMPLETE
n130-019-195:1129998:1130564 [7] NCCL INFO comm 0x7fa7940028b0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 - Init COMPLETE
n130-019-195:1129985:1130549 [0] NCCL INFO comm 0x7f2dc00028b0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 - Init COMPLETE
n130-019-195:1129985:1129985 [0] NCCL INFO Launch mode Parallel
n130-019-195:1129993:1130567 [4] NCCL INFO comm 0x7f9e140028b0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 - Init COMPLETE
git:
  sha: 1f9db732032449839b300eb88ff500f6665c259e, status: has uncommited changes, branch: fs_deformable_detr

number of params: 6711372
data/coco/cocosplit_self/seed3/full_box_10shot_trainval.json
id map
{1: 60, 2: 61, 3: 62, 4: 63, 5: 64, 6: 65, 7: 66, 9: 67, 16: 68, 17: 69, 18: 70, 19: 71, 20: 72, 21: 73, 44: 74, 62: 75, 63: 76, 64: 77, 67: 78, 72: 79, 8: 0, 10: 1, 11: 2, 13: 3, 14: 4, 15: 5, 22: 6, 23: 7, 24: 8, 25: 9, 27: 10, 28: 11, 31: 12, 32: 13, 33: 14, 34: 15, 35: 16, 36: 17, 37: 18, 38: 19, 39: 20, 40: 21, 41: 22, 42: 23, 43: 24, 46: 25, 47: 26, 48: 27, 49: 28, 50: 29, 51: 30, 52: 31, 53: 32, 54: 33, 55: 34, 56: 35, 57: 36, 58: 37, 59: 38, 60: 39, 61: 40, 65: 41, 70: 42, 73: 43, 74: 44, 75: 45, 76: 46, 77: 47, 78: 48, 79: 49, 80: 50, 81: 51, 82: 52, 84: 53, 85: 54, 86: 55, 87: 56, 88: 57, 89: 58, 90: 59}
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
dataset_name : coco_all_seed_3_10_shot, image nums : 700, anno nums : 800
data/coco/cocosplit_self/datasplit/5k.json
id map
{1: 60, 2: 61, 3: 62, 4: 63, 5: 64, 6: 65, 7: 66, 9: 67, 16: 68, 17: 69, 18: 70, 19: 71, 20: 72, 21: 73, 44: 74, 62: 75, 63: 76, 64: 77, 67: 78, 72: 79, 8: 0, 10: 1, 11: 2, 13: 3, 14: 4, 15: 5, 22: 6, 23: 7, 24: 8, 25: 9, 27: 10, 28: 11, 31: 12, 32: 13, 33: 14, 34: 15, 35: 16, 36: 17, 37: 18, 38: 19, 39: 20, 40: 21, 41: 22, 42: 23, 43: 24, 46: 25, 47: 26, 48: 27, 49: 28, 50: 29, 51: 30, 52: 31, 53: 32, 54: 33, 55: 34, 56: 35, 57: 36, 58: 37, 59: 38, 60: 39, 61: 40, 65: 41, 70: 42, 73: 43, 74: 44, 75: 45, 76: 46, 77: 47, 78: 48, 79: 49, 80: 50, 81: 51, 82: 52, 84: 53, 85: 54, 86: 55, 87: 56, 88: 57, 89: 58, 90: 59}
loading annotations into memory...
Done (t=0.53s)
creating index...
index created!
dataset_name : coco_val, image nums : 5000, anno nums : 35511
transformer.level_embed False
transformer.encoder.layers.0.self_attn.sampling_offsets.weight False
transformer.encoder.layers.0.self_attn.sampling_offsets.bias False
transformer.encoder.layers.0.self_attn.attention_weights.weight False
transformer.encoder.layers.0.self_attn.attention_weights.bias False
transformer.encoder.layers.0.self_attn.value_proj.weight False
transformer.encoder.layers.0.self_attn.value_proj.bias False
transformer.encoder.layers.0.self_attn.output_proj.weight False
transformer.encoder.layers.0.self_attn.output_proj.bias False
transformer.encoder.layers.0.norm1.weight False
transformer.encoder.layers.0.norm1.bias False
transformer.encoder.layers.0.linear1.weight False
transformer.encoder.layers.0.linear1.bias False
transformer.encoder.layers.0.linear2.weight False
transformer.encoder.layers.0.linear2.bias False
transformer.encoder.layers.0.norm2.weight False
transformer.encoder.layers.0.norm2.bias False
transformer.encoder.layers.1.self_attn.sampling_offsets.weight False
transformer.encoder.layers.1.self_attn.sampling_offsets.bias False
transformer.encoder.layers.1.self_attn.attention_weights.weight False
transformer.encoder.layers.1.self_attn.attention_weights.bias False
transformer.encoder.layers.1.self_attn.value_proj.weight False
transformer.encoder.layers.1.self_attn.value_proj.bias False
transformer.encoder.layers.1.self_attn.output_proj.weight False
transformer.encoder.layers.1.self_attn.output_proj.bias False
transformer.encoder.layers.1.norm1.weight False
transformer.encoder.layers.1.norm1.bias False
transformer.encoder.layers.1.linear1.weight False
transformer.encoder.layers.1.linear1.bias False
transformer.encoder.layers.1.linear2.weight False
transformer.encoder.layers.1.linear2.bias False
transformer.encoder.layers.1.norm2.weight False
transformer.encoder.layers.1.norm2.bias False
transformer.encoder.layers.2.self_attn.sampling_offsets.weight False
transformer.encoder.layers.2.self_attn.sampling_offsets.bias False
transformer.encoder.layers.2.self_attn.attention_weights.weight False
transformer.encoder.layers.2.self_attn.attention_weights.bias False
transformer.encoder.layers.2.self_attn.value_proj.weight False
transformer.encoder.layers.2.self_attn.value_proj.bias False
transformer.encoder.layers.2.self_attn.output_proj.weight False
transformer.encoder.layers.2.self_attn.output_proj.bias False
transformer.encoder.layers.2.norm1.weight False
transformer.encoder.layers.2.norm1.bias False
transformer.encoder.layers.2.linear1.weight False
transformer.encoder.layers.2.linear1.bias False
transformer.encoder.layers.2.linear2.weight False
transformer.encoder.layers.2.linear2.bias False
transformer.encoder.layers.2.norm2.weight False
transformer.encoder.layers.2.norm2.bias False
transformer.encoder.layers.3.self_attn.sampling_offsets.weight False
transformer.encoder.layers.3.self_attn.sampling_offsets.bias False
transformer.encoder.layers.3.self_attn.attention_weights.weight False
transformer.encoder.layers.3.self_attn.attention_weights.bias False
transformer.encoder.layers.3.self_attn.value_proj.weight False
transformer.encoder.layers.3.self_attn.value_proj.bias False
transformer.encoder.layers.3.self_attn.output_proj.weight False
transformer.encoder.layers.3.self_attn.output_proj.bias False
transformer.encoder.layers.3.norm1.weight False
transformer.encoder.layers.3.norm1.bias False
transformer.encoder.layers.3.linear1.weight False
transformer.encoder.layers.3.linear1.bias False
transformer.encoder.layers.3.linear2.weight False
transformer.encoder.layers.3.linear2.bias False
transformer.encoder.layers.3.norm2.weight False
transformer.encoder.layers.3.norm2.bias False
transformer.encoder.layers.4.self_attn.sampling_offsets.weight False
transformer.encoder.layers.4.self_attn.sampling_offsets.bias False
transformer.encoder.layers.4.self_attn.attention_weights.weight False
transformer.encoder.layers.4.self_attn.attention_weights.bias False
transformer.encoder.layers.4.self_attn.value_proj.weight False
transformer.encoder.layers.4.self_attn.value_proj.bias False
transformer.encoder.layers.4.self_attn.output_proj.weight False
transformer.encoder.layers.4.self_attn.output_proj.bias False
transformer.encoder.layers.4.norm1.weight False
transformer.encoder.layers.4.norm1.bias False
transformer.encoder.layers.4.linear1.weight False
transformer.encoder.layers.4.linear1.bias False
transformer.encoder.layers.4.linear2.weight False
transformer.encoder.layers.4.linear2.bias False
transformer.encoder.layers.4.norm2.weight False
transformer.encoder.layers.4.norm2.bias False
transformer.encoder.layers.5.self_attn.sampling_offsets.weight False
transformer.encoder.layers.5.self_attn.sampling_offsets.bias False
transformer.encoder.layers.5.self_attn.attention_weights.weight False
transformer.encoder.layers.5.self_attn.attention_weights.bias False
transformer.encoder.layers.5.self_attn.value_proj.weight False
transformer.encoder.layers.5.self_attn.value_proj.bias False
transformer.encoder.layers.5.self_attn.output_proj.weight False
transformer.encoder.layers.5.self_attn.output_proj.bias False
transformer.encoder.layers.5.norm1.weight False
transformer.encoder.layers.5.norm1.bias False
transformer.encoder.layers.5.linear1.weight False
transformer.encoder.layers.5.linear1.bias False
transformer.encoder.layers.5.linear2.weight False
transformer.encoder.layers.5.linear2.bias False
transformer.encoder.layers.5.norm2.weight False
transformer.encoder.layers.5.norm2.bias False
transformer.decoder.layers.0.cross_attn.sampling_offsets.weight False
transformer.decoder.layers.0.cross_attn.sampling_offsets.bias False
transformer.decoder.layers.0.cross_attn.attention_weights.weight False
transformer.decoder.layers.0.cross_attn.attention_weights.bias False
transformer.decoder.layers.0.cross_attn.value_proj.weight False
transformer.decoder.layers.0.cross_attn.value_proj.bias False
transformer.decoder.layers.0.cross_attn.output_proj.weight False
transformer.decoder.layers.0.cross_attn.output_proj.bias False
transformer.decoder.layers.0.norm1.weight False
transformer.decoder.layers.0.norm1.bias False
transformer.decoder.layers.0.self_attn.in_proj_weight False
transformer.decoder.layers.0.self_attn.in_proj_bias False
transformer.decoder.layers.0.self_attn.out_proj.weight False
transformer.decoder.layers.0.self_attn.out_proj.bias False
transformer.decoder.layers.0.norm2.weight False
transformer.decoder.layers.0.norm2.bias False
transformer.decoder.layers.0.linear1.weight False
transformer.decoder.layers.0.linear1.bias False
transformer.decoder.layers.0.linear2.weight False
transformer.decoder.layers.0.linear2.bias False
transformer.decoder.layers.0.norm3.weight False
transformer.decoder.layers.0.norm3.bias False
transformer.decoder.layers.1.cross_attn.sampling_offsets.weight False
transformer.decoder.layers.1.cross_attn.sampling_offsets.bias False
transformer.decoder.layers.1.cross_attn.attention_weights.weight False
transformer.decoder.layers.1.cross_attn.attention_weights.bias False
transformer.decoder.layers.1.cross_attn.value_proj.weight False
transformer.decoder.layers.1.cross_attn.value_proj.bias False
transformer.decoder.layers.1.cross_attn.output_proj.weight False
transformer.decoder.layers.1.cross_attn.output_proj.bias False
transformer.decoder.layers.1.norm1.weight False
transformer.decoder.layers.1.norm1.bias False
transformer.decoder.layers.1.self_attn.in_proj_weight False
transformer.decoder.layers.1.self_attn.in_proj_bias False
transformer.decoder.layers.1.self_attn.out_proj.weight False
transformer.decoder.layers.1.self_attn.out_proj.bias False
transformer.decoder.layers.1.norm2.weight False
transformer.decoder.layers.1.norm2.bias False
transformer.decoder.layers.1.linear1.weight False
transformer.decoder.layers.1.linear1.bias False
transformer.decoder.layers.1.linear2.weight False
transformer.decoder.layers.1.linear2.bias False
transformer.decoder.layers.1.norm3.weight False
transformer.decoder.layers.1.norm3.bias False
transformer.decoder.layers.2.cross_attn.sampling_offsets.weight False
transformer.decoder.layers.2.cross_attn.sampling_offsets.bias False
transformer.decoder.layers.2.cross_attn.attention_weights.weight False
transformer.decoder.layers.2.cross_attn.attention_weights.bias False
transformer.decoder.layers.2.cross_attn.value_proj.weight False
transformer.decoder.layers.2.cross_attn.value_proj.bias False
transformer.decoder.layers.2.cross_attn.output_proj.weight False
transformer.decoder.layers.2.cross_attn.output_proj.bias False
transformer.decoder.layers.2.norm1.weight False
transformer.decoder.layers.2.norm1.bias False
transformer.decoder.layers.2.self_attn.in_proj_weight False
transformer.decoder.layers.2.self_attn.in_proj_bias False
transformer.decoder.layers.2.self_attn.out_proj.weight False
transformer.decoder.layers.2.self_attn.out_proj.bias False
transformer.decoder.layers.2.norm2.weight False
transformer.decoder.layers.2.norm2.bias False
transformer.decoder.layers.2.linear1.weight False
transformer.decoder.layers.2.linear1.bias False
transformer.decoder.layers.2.linear2.weight False
transformer.decoder.layers.2.linear2.bias False
transformer.decoder.layers.2.norm3.weight False
transformer.decoder.layers.2.norm3.bias False
transformer.decoder.layers.3.cross_attn.sampling_offsets.weight False
transformer.decoder.layers.3.cross_attn.sampling_offsets.bias False
transformer.decoder.layers.3.cross_attn.attention_weights.weight False
transformer.decoder.layers.3.cross_attn.attention_weights.bias False
transformer.decoder.layers.3.cross_attn.value_proj.weight False
transformer.decoder.layers.3.cross_attn.value_proj.bias False
transformer.decoder.layers.3.cross_attn.output_proj.weight False
transformer.decoder.layers.3.cross_attn.output_proj.bias False
transformer.decoder.layers.3.norm1.weight False
transformer.decoder.layers.3.norm1.bias False
transformer.decoder.layers.3.self_attn.in_proj_weight False
transformer.decoder.layers.3.self_attn.in_proj_bias False
transformer.decoder.layers.3.self_attn.out_proj.weight False
transformer.decoder.layers.3.self_attn.out_proj.bias False
transformer.decoder.layers.3.norm2.weight False
transformer.decoder.layers.3.norm2.bias False
transformer.decoder.layers.3.linear1.weight False
transformer.decoder.layers.3.linear1.bias False
transformer.decoder.layers.3.linear2.weight False
transformer.decoder.layers.3.linear2.bias False
transformer.decoder.layers.3.norm3.weight False
transformer.decoder.layers.3.norm3.bias False
transformer.decoder.layers.4.cross_attn.sampling_offsets.weight False
transformer.decoder.layers.4.cross_attn.sampling_offsets.bias False
transformer.decoder.layers.4.cross_attn.attention_weights.weight False
transformer.decoder.layers.4.cross_attn.attention_weights.bias False
transformer.decoder.layers.4.cross_attn.value_proj.weight False
transformer.decoder.layers.4.cross_attn.value_proj.bias False
transformer.decoder.layers.4.cross_attn.output_proj.weight False
transformer.decoder.layers.4.cross_attn.output_proj.bias False
transformer.decoder.layers.4.norm1.weight False
transformer.decoder.layers.4.norm1.bias False
transformer.decoder.layers.4.self_attn.in_proj_weight False
transformer.decoder.layers.4.self_attn.in_proj_bias False
transformer.decoder.layers.4.self_attn.out_proj.weight False
transformer.decoder.layers.4.self_attn.out_proj.bias False
transformer.decoder.layers.4.norm2.weight False
transformer.decoder.layers.4.norm2.bias False
transformer.decoder.layers.4.linear1.weight False
transformer.decoder.layers.4.linear1.bias False
transformer.decoder.layers.4.linear2.weight False
transformer.decoder.layers.4.linear2.bias False
transformer.decoder.layers.4.norm3.weight False
transformer.decoder.layers.4.norm3.bias False
transformer.decoder.layers.5.cross_attn.sampling_offsets.weight False
transformer.decoder.layers.5.cross_attn.sampling_offsets.bias False
transformer.decoder.layers.5.cross_attn.attention_weights.weight False
transformer.decoder.layers.5.cross_attn.attention_weights.bias False
transformer.decoder.layers.5.cross_attn.value_proj.weight False
transformer.decoder.layers.5.cross_attn.value_proj.bias False
transformer.decoder.layers.5.cross_attn.output_proj.weight False
transformer.decoder.layers.5.cross_attn.output_proj.bias False
transformer.decoder.layers.5.norm1.weight False
transformer.decoder.layers.5.norm1.bias False
transformer.decoder.layers.5.self_attn.in_proj_weight False
transformer.decoder.layers.5.self_attn.in_proj_bias False
transformer.decoder.layers.5.self_attn.out_proj.weight False
transformer.decoder.layers.5.self_attn.out_proj.bias False
transformer.decoder.layers.5.norm2.weight False
transformer.decoder.layers.5.norm2.bias False
transformer.decoder.layers.5.linear1.weight False
transformer.decoder.layers.5.linear1.bias False
transformer.decoder.layers.5.linear2.weight False
transformer.decoder.layers.5.linear2.bias False
transformer.decoder.layers.5.norm3.weight False
transformer.decoder.layers.5.norm3.bias False
transformer.decoder.bbox_embed.0.layers.0.weight True
transformer.decoder.bbox_embed.0.layers.0.bias True
transformer.decoder.bbox_embed.0.layers.1.weight True
transformer.decoder.bbox_embed.0.layers.1.bias True
transformer.decoder.bbox_embed.0.layers.2.weight True
transformer.decoder.bbox_embed.0.layers.2.bias True
transformer.decoder.bbox_embed.1.layers.0.weight True
transformer.decoder.bbox_embed.1.layers.0.bias True
transformer.decoder.bbox_embed.1.layers.1.weight True
transformer.decoder.bbox_embed.1.layers.1.bias True
transformer.decoder.bbox_embed.1.layers.2.weight True
transformer.decoder.bbox_embed.1.layers.2.bias True
transformer.decoder.bbox_embed.2.layers.0.weight True
transformer.decoder.bbox_embed.2.layers.0.bias True
transformer.decoder.bbox_embed.2.layers.1.weight True
transformer.decoder.bbox_embed.2.layers.1.bias True
transformer.decoder.bbox_embed.2.layers.2.weight True
transformer.decoder.bbox_embed.2.layers.2.bias True
transformer.decoder.bbox_embed.3.layers.0.weight True
transformer.decoder.bbox_embed.3.layers.0.bias True
transformer.decoder.bbox_embed.3.layers.1.weight True
transformer.decoder.bbox_embed.3.layers.1.bias True
transformer.decoder.bbox_embed.3.layers.2.weight True
transformer.decoder.bbox_embed.3.layers.2.bias True
transformer.decoder.bbox_embed.4.layers.0.weight True
transformer.decoder.bbox_embed.4.layers.0.bias True
transformer.decoder.bbox_embed.4.layers.1.weight True
transformer.decoder.bbox_embed.4.layers.1.bias True
transformer.decoder.bbox_embed.4.layers.2.weight True
transformer.decoder.bbox_embed.4.layers.2.bias True
transformer.decoder.bbox_embed.5.layers.0.weight True
transformer.decoder.bbox_embed.5.layers.0.bias True
transformer.decoder.bbox_embed.5.layers.1.weight True
transformer.decoder.bbox_embed.5.layers.1.bias True
transformer.decoder.bbox_embed.5.layers.2.weight True
transformer.decoder.bbox_embed.5.layers.2.bias True
transformer.decoder.bbox_embed.6.layers.0.weight True
transformer.decoder.bbox_embed.6.layers.0.bias True
transformer.decoder.bbox_embed.6.layers.1.weight True
transformer.decoder.bbox_embed.6.layers.1.bias True
transformer.decoder.bbox_embed.6.layers.2.weight True
transformer.decoder.bbox_embed.6.layers.2.bias True
transformer.decoder.class_embed.0.weight True
transformer.decoder.class_embed.0.bias True
transformer.decoder.class_embed.1.weight True
transformer.decoder.class_embed.1.bias True
transformer.decoder.class_embed.2.weight True
transformer.decoder.class_embed.2.bias True
transformer.decoder.class_embed.3.weight True
transformer.decoder.class_embed.3.bias True
transformer.decoder.class_embed.4.weight True
transformer.decoder.class_embed.4.bias True
transformer.decoder.class_embed.5.weight True
transformer.decoder.class_embed.5.bias True
transformer.decoder.class_embed.6.weight True
transformer.decoder.class_embed.6.bias True
transformer.enc_output.weight False
transformer.enc_output.bias False
transformer.enc_output_norm.weight False
transformer.enc_output_norm.bias False
transformer.pos_trans.weight False
transformer.pos_trans.bias False
transformer.pos_trans_norm.weight False
transformer.pos_trans_norm.bias False
input_proj.0.0.weight True
input_proj.0.0.bias True
input_proj.0.1.weight True
input_proj.0.1.bias True
input_proj.1.0.weight True
input_proj.1.0.bias True
input_proj.1.1.weight True
input_proj.1.1.bias True
input_proj.2.0.weight True
input_proj.2.0.bias True
input_proj.2.1.weight True
input_proj.2.1.bias True
input_proj.3.0.weight True
input_proj.3.0.bias True
input_proj.3.1.weight True
input_proj.3.1.bias True
backbone.0.body.conv1.weight False
backbone.0.body.layer1.0.conv1.weight False
backbone.0.body.layer1.0.conv2.weight False
backbone.0.body.layer1.0.conv3.weight False
backbone.0.body.layer1.0.downsample.0.weight False
backbone.0.body.layer1.1.conv1.weight False
backbone.0.body.layer1.1.conv2.weight False
backbone.0.body.layer1.1.conv3.weight False
backbone.0.body.layer1.2.conv1.weight False
backbone.0.body.layer1.2.conv2.weight False
backbone.0.body.layer1.2.conv3.weight False
backbone.0.body.layer2.0.conv1.weight False
backbone.0.body.layer2.0.conv2.weight False
backbone.0.body.layer2.0.conv3.weight False
backbone.0.body.layer2.0.downsample.0.weight False
backbone.0.body.layer2.1.conv1.weight False
backbone.0.body.layer2.1.conv2.weight False
backbone.0.body.layer2.1.conv3.weight False
backbone.0.body.layer2.2.conv1.weight False
backbone.0.body.layer2.2.conv2.weight False
backbone.0.body.layer2.2.conv3.weight False
backbone.0.body.layer2.3.conv1.weight False
backbone.0.body.layer2.3.conv2.weight False
backbone.0.body.layer2.3.conv3.weight False
backbone.0.body.layer3.0.conv1.weight False
backbone.0.body.layer3.0.conv2.weight False
backbone.0.body.layer3.0.conv3.weight False
backbone.0.body.layer3.0.downsample.0.weight False
backbone.0.body.layer3.1.conv1.weight False
backbone.0.body.layer3.1.conv2.weight False
backbone.0.body.layer3.1.conv3.weight False
backbone.0.body.layer3.2.conv1.weight False
backbone.0.body.layer3.2.conv2.weight False
backbone.0.body.layer3.2.conv3.weight False
backbone.0.body.layer3.3.conv1.weight False
backbone.0.body.layer3.3.conv2.weight False
backbone.0.body.layer3.3.conv3.weight False
backbone.0.body.layer3.4.conv1.weight False
backbone.0.body.layer3.4.conv2.weight False
backbone.0.body.layer3.4.conv3.weight False
backbone.0.body.layer3.5.conv1.weight False
backbone.0.body.layer3.5.conv2.weight False
backbone.0.body.layer3.5.conv3.weight False
backbone.0.body.layer4.0.conv1.weight False
backbone.0.body.layer4.0.conv2.weight False
backbone.0.body.layer4.0.conv3.weight False
backbone.0.body.layer4.0.downsample.0.weight False
backbone.0.body.layer4.1.conv1.weight False
backbone.0.body.layer4.1.conv2.weight False
backbone.0.body.layer4.1.conv3.weight False
backbone.0.body.layer4.2.conv1.weight False
backbone.0.body.layer4.2.conv2.weight False
backbone.0.body.layer4.2.conv3.weight False
Start training
Epoch: [0]  [ 0/22]  eta: 0:00:24  lr: 0.000400  class_error: 96.88  grad_norm: 10.35  loss: 29.8161 (29.8161)  loss_bbox: 0.7550 (0.7550)  loss_bbox_0: 0.8656 (0.8656)  loss_bbox_1: 0.7922 (0.7922)  loss_bbox_2: 0.7972 (0.7972)  loss_bbox_3: 0.7819 (0.7819)  loss_bbox_4: 0.7819 (0.7819)  loss_bbox_enc: 0.1525 (0.1525)  loss_ce: 2.2776 (2.2776)  loss_ce_0: 2.2694 (2.2694)  loss_ce_1: 2.2518 (2.2518)  loss_ce_2: 2.2659 (2.2659)  loss_ce_3: 2.2649 (2.2649)  loss_ce_4: 2.2795 (2.2795)  loss_ce_enc: 4.1589 (4.1589)  loss_giou: 1.1133 (1.1133)  loss_giou_0: 1.2286 (1.2286)  loss_giou_1: 1.1630 (1.1630)  loss_giou_2: 1.1260 (1.1260)  loss_giou_3: 1.1181 (1.1181)  loss_giou_4: 1.1181 (1.1181)  loss_giou_enc: 0.2548 (0.2548)  cardinality_error_unscaled: 98.9062 (98.9062)  cardinality_error_0_unscaled: 98.8438 (98.8438)  cardinality_error_1_unscaled: 98.8125 (98.8125)  cardinality_error_2_unscaled: 98.6562 (98.6562)  cardinality_error_3_unscaled: 98.9062 (98.9062)  cardinality_error_4_unscaled: 95.6562 (95.6562)  cardinality_error_enc_unscaled: 17562.8125 (17562.8125)  class_error_unscaled: 96.8750 (96.8750)  loss_bbox_unscaled: 0.1510 (0.1510)  loss_bbox_0_unscaled: 0.1731 (0.1731)  loss_bbox_1_unscaled: 0.1584 (0.1584)  loss_bbox_2_unscaled: 0.1594 (0.1594)  loss_bbox_3_unscaled: 0.1564 (0.1564)  loss_bbox_4_unscaled: 0.1564 (0.1564)  loss_bbox_enc_unscaled: 0.0305 (0.0305)  loss_ce_unscaled: 1.1388 (1.1388)  loss_ce_0_unscaled: 1.1347 (1.1347)  loss_ce_1_unscaled: 1.1259 (1.1259)  loss_ce_2_unscaled: 1.1329 (1.1329)  loss_ce_3_unscaled: 1.1324 (1.1324)  loss_ce_4_unscaled: 1.1397 (1.1397)  loss_ce_enc_unscaled: 2.0795 (2.0795)  loss_giou_unscaled: 0.5566 (0.5566)  loss_giou_0_unscaled: 0.6143 (0.6143)  loss_giou_1_unscaled: 0.5815 (0.5815)  loss_giou_2_unscaled: 0.5630 (0.5630)  loss_giou_3_unscaled: 0.5590 (0.5590)  loss_giou_4_unscaled: 0.5591 (0.5591)  loss_giou_enc_unscaled: 0.1274 (0.1274)  time: 1.1285  data: 0.0001  max mem: 9195
